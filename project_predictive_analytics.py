# -*- coding: utf-8 -*-
"""Project_Predictive_Analytics.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1uJ0ZbmZaduFiCenTY0LS2lsyxP4IRMdT

<h1> <b>Prediksi Harga Rumah<b> <h1>

# Import Library

Mengimpor library yang dibutuhkan
"""

# Commented out IPython magic to ensure Python compatibility.
# Import library
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import random as rnd
# %matplotlib inline
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import r2_score
from sklearn.metrics import mean_squared_error
from sklearn.neighbors import KNeighborsRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.ensemble import AdaBoostRegressor

"""# Data Loading

Mengunduh data di https://www.kaggle.com/datasets/harlfoxem/housesalesprediction 

Kolom atau variabel pada dataset adalah:

*   id: ID unik untuk setiap rumah yang terjual
*   date: Tanggal penjualan rumah
*   price: Harga setiap rumah terjual
*   bedrooms: Jumlah kamar tidur
*   bathrooms: Jumlah kamar mandi, di mana .5 merupakan kamar dengan toilet tetapi tanpa pancuran
*   sqft_living: Ukuran persegi ruang tamu interior apartemen
*   sqft_lot: Ukuran persegi luas tanah
*   floors: Jumlah lantai
*   waterfront: - Variabel dummy apakah apartemen menghadap ke tepi laut atau tidak
*   view: Indeks dari 0 hingga 4 tentang seberapa bagus tampilan properti itu
*   condition: - Indeks dari 1 hingga 5 pada kondisi apartemen,
*   grade: Indeks dari 1 hingga 13, di mana 1-3 tidak sesuai dengan konstruksi dan desain bangunan, 7 memiliki tingkat konstruksi dan desain rata-rata, dan 11-13 memiliki tingkat kualitas konstruksi dan desain yang tinggi.
*   sqft_above: Rekaman persegi ruang interior perumahan yang berada di atas permukaan tanah
*   sqft_basement: Rekaman persegi ruang interior perumahan yang berada di bawah permukaan tanah
*   yr_built: Tahun rumah pertama kali dibangun
*   yr_renovated: Tahun renovasi terakhir rumah
*   zipcode: Kode pos di area mana rumah itu berada
*   lat: Lintang (latitudinal)
*   long: Bujur (longitudinal)
*   sqft_living15: Rekaman persegi ruang hidup perumahan interior untuk 15 tetangga terdekat
*   sqft_lot15: Luas tanah kavling 15 tetangga terdekat


"""

# Loading dataset
dataset = '/content/kc_house_data.csv'
house = pd.read_csv(dataset)
house

"""# Explanatory Data Analysis

Melakukan beberapa tahapan sebagai berikut : 

1.   Deskripsi Variabel
2.   Menangani missing value dan outliers
3.   Analisis Univariate
4.   Analisis Multivariate

<h2> Dekspripsi Variabel <h2>
"""

# Cek info dataset
house.info()

"""Dataset terdiri dari:

*   5 variabel bertipe float
*   15 variabel bertipe integer
*   1 variabel bertipe object




"""

# Cek deskripsi data
house.describe()

"""<h2> Menangani missing value <h2>"""

# Cek Missing Value
house.isnull().sum()

"""Dataset tidak memiliki missing value pada setiap kolom nya. Namun jika terdapat missing value, dapat diatasi dengan cara mengganti missing value dengan nilai mean untuk data numerik, atau nilai modus untuk data kategorikal.

<h2> Menangani Outliers <h2>

Outliers merupakan sampel yang nilainya sangat jauh dari cakupan umum data utama. Outliers dapat dideteksi dengan teknik visualisasi data (boxplot), dan ditangani dengan teknik IQR method.
"""

# Visualisasi boxplot untuk kolom price
sns.boxplot(x=house['price'])

# Visualisasi boxplot untuk kolom condition
sns.boxplot(x=house['condition'])

# IQR method
Q1 = house.quantile(0.25)
Q3 = house.quantile(0.75)
IQR=Q3-Q1
house=house[~((house<(Q1-1.5*IQR))|(house>(Q3+1.5*IQR))).any(axis=1)]
 
# Cek ukuran dataset setelah kita drop outliers
house.shape

"""<h2> EDA - Analisis Univariate <h2>

Analisis univariate merupakan proses untuk mengeksplorasi dan menjelaskan setiap variabel dalam kumpulan data secara terpisah. 
"""

# Memisahkan fitur dataset menjadi 2, yaitu numerical dan categorical
numerical = house.select_dtypes(include=np.number).columns.tolist()
categorical = house.select_dtypes(include=["object"]).columns.tolist()

numerical

categorical

# Analisa fitur kategori
feature = categorical[0]
count = house[feature].value_counts()
percent = 100*house[feature].value_counts(normalize=True)
df = pd.DataFrame({'jumlah sampel':count, 'persentase':percent.round(1)})
print(df)
count.plot(kind='bar', title=feature);

# Analisa fitur numerical
house.hist(bins=50, figsize=(20,15))
plt.show()

"""Dari visualisasi pairplot diatas, kita bisa melihat bahwa :  

*   Jumlah terbanyak unit rumah memiliki 3 bedroom/kamar 
*   Jumlah rumah yang memiliki 3 lantai kurang dari 1000 unit
*   Sekitar 7000 unit rumah memiliki tingkat konstruksi dan desain rata-rata (grade=7)




"""

# Menghapus fitur yang hanya memiliki 1 nilai (yaitu 0) karena tidak memiliki korelasi dengan fitur lainnya
house = house.drop(columns=['view','yr_renovated','waterfront'])

"""<h2> Analisis Multivariate <h2>

Multivariate EDA menunjukkan hubungan antara dua atau lebih variabel pada data.
"""

# Analisa fitur price dengan fitur date
sns.catplot(x='date', y="price", kind="bar", dodge=False, height = 4, aspect = 3,  data=house, palette="Set3")
plt.title("Rata-rata price(harga) Relatif terhadap - {}".format('date'))

"""Fitur date memiliki terlalu banyak variasi, sehingga fitur date tidak mempengaruhi fitur price"""

# Menghapus fitur date 
house = house.drop(columns=['date'])

# Analisa hubungan antar fitur numerik dengan fungsi pairplot()
sns.pairplot(house, diag_kind = 'kde')

# Analisa hubungan antar fitur numerik dengan fungsi heatmap
mask = np.zeros_like(house.corr().abs(), dtype=np.bool)
mask[np.triu_indices_from(mask)] = True

f, ax = plt.subplots(figsize=(16, 12))
plt.title('Pearson Correlation Matrix', fontsize=25)

sns.heatmap(house.corr(), linewidth=0.25, vmax=0.7, square=True, cmap='BuPu', 
           linecolor='w', annot=True, annot_kws={'size': 8}, mask=mask, cbar_kws={'shrink': .9});

# Mencari fitur yang mempunyai nilai korelasi tinggi terhadap fitur 'price' sebagai fitur TARGET 
price_corr = house.corr()['price']
low_features = price_corr[(price_corr<0.25)]
house.drop(low_features.index,axis=1,inplace=True)
print('Training Features shape:',house.shape)
house.columns

"""Fitur yang memiliki korelasi cukup kuat dengan fitur "price" adalah :
'bathrooms', 'sqft_living', 'grade', 'sqft_above',
       'lat', 'sqft_living15'

<h2> Data Preparation <h2>

Transformasi data menjadi bentuk yang cocok untuk proses pemodelan.

<h4> Train-Test Split <h4>

 Proporsi pembagian data latih dan uji adalah 90:10
"""

from sklearn.model_selection import train_test_split
 
X = house.drop(["price"],axis =1)
y = house["price"]  
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 123)

#cek jumlah sampel
print(f'Total # of sample in whole dataset: {len(X)}')
print(f'Total # of sample in train dataset: {len(X_train)}')
print(f'Total # of sample in test dataset: {len(X_test)}')

"""<h4> Standarisasi <h4>

Standarisasi menggunakan teknik StandarScaler dari library Scikitlearn, 

StandardScaler melakukan proses standarisasi fitur dengan mengurangkan mean (nilai rata-rata) kemudian membaginya dengan standar deviasi untuk menggeser distribusi.  StandardScaler menghasilkan distribusi dengan standar deviasi sama dengan 1 dan mean sama dengan 0.
"""

from sklearn.preprocessing import StandardScaler
 
features = ['bathrooms', 'sqft_living', 'grade', 'sqft_above',
       'lat', 'sqft_living15']
scaler = StandardScaler()
scaler.fit(X_train[features])
X_train[features] = scaler.transform(X_train.loc[:, features])
X_train[features].head()

"""<h2> Model Development <h2>

Model development adalah tahapan di mana kita menggunakan algoritma machine learning untuk menjawab problem statement dari tahap business understanding.
Pada tahap ini, kita akan mengembangkan model machine learning dengan tiga algoritma. Kemudian, kita akan mengevaluasi performa masing-masing algoritma dan menentukan algoritma mana yang memberikan hasil prediksi terbaik. Ketiga algoritma yang akan kita gunakan, antara lain:

1.   K-Nearest Neighbors
2.   Random Forest
3.   Boosting Algorithm

"""

# Siapkan dataframe untuk analisis model
models = pd.DataFrame(index=['KNN', 'RandomForest', 'Boosting'], 
                      columns=['train_mse', 'test_mse'])

"""K-Nearest Neighbor"""

knn = KNeighborsRegressor(n_neighbors=10)
knn.fit(X_train, y_train)
 
models.loc['KNN','train_mse'] = mean_squared_error(y_true=y_train, y_pred=knn.predict(X_train))/1e3
models.loc['KNN','test_mse'] = mean_squared_error(y_true=y_test, y_pred=knn.predict(X_test))/1e3

"""Random Forest"""

randomforest = RandomForestRegressor(n_estimators=50, max_depth=16, random_state=55, n_jobs=-1)
randomforest.fit(X_train, y_train)
 
models.loc['RandomForest','train_mse'] = mean_squared_error(y_true=y_train, y_pred=randomforest.predict(X_train))/1e3
models.loc['RandomForest','test_mse'] = mean_squared_error(y_true=y_test, y_pred=randomforest.predict(X_test))/1e3

"""Boosting Algorithm"""

boosting = AdaBoostRegressor(learning_rate=0.05, random_state=55)                             
boosting.fit(X_train, y_train)

models.loc['Boosting','train_mse'] = mean_squared_error(y_true=y_train, y_pred=boosting.predict(X_train))/1e3
models.loc['Boosting','test_mse'] = mean_squared_error(y_true=y_test, y_pred=boosting.predict(X_test))/1e3

models

fig, ax = plt.subplots()
models.sort_values(by='test_mse', ascending=False).plot(kind='barh', ax=ax, zorder=3)
ax.grid(zorder=0)

# Prediksi dengan 10 data
prediksi = X_test.iloc[100:110].copy()
pred_dict = {'y_true':y_test[100:110]}
model_dict = {'KNN': knn, 'RandomForest': randomforest, 'Boosting': boosting}
for name, model in model_dict.items():
    pred_dict['prediksi_'+name] = model.predict(prediksi).round(1)
 
pd.DataFrame(pred_dict)